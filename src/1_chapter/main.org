* activate
#+begin_src emacs-lisp
  (pyvenv-activate "~/project/kaggle_win/")
#+end_src

#+RESULTS:

* タスクと評価指標
#+begin_src python :session
import pandas as pd

# 学習データ、テストデータの読み込み
train = pd.read_csv("./input/train.csv")
test = pd.read_csv("./input/test.csv")

# 学習データを特徴量と目的変数に分ける
train_x = train.drop(["Survived"], axis=1)
train_y = train["Survived"]

# テストデータは特徴量のみなので、そのままで良い
test_x = test.copy()
#+end_src

#+RESULTS:

#+begin_src python :session
train_x
#+end_src

#+RESULTS:
#+begin_example
     PassengerId  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked
0              1       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   7.2500   NaN        S
1              2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599  71.2833   C85        C
2              3       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S
3              4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803  53.1000  C123        S
4              5       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   8.0500   NaN        S
..           ...     ...                                                ...     ...   ...    ...    ...               ...      ...   ...      ...
886          887       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536  13.0000   NaN        S
887          888       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053  30.0000   B42        S
888          889       3           Johnston, Miss. Catherine Helen "Carrie"  female   NaN      1      2        W./C. 6607  23.4500   NaN        S
889          890       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369  30.0000  C148        C
890          891       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   7.7500   NaN        Q

[891 rows x 11 columns]
#+end_example

列の名前が知りたい
#+begin_src python :session
train_x.columns
#+end_src

#+RESULTS:
: Index(['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',
:        'Ticket', 'Fare', 'Cabin', 'Embarked'],
:       dtype='object')

* 特徴量の作成
GBDT（勾配ブースティング木）というモデルを利用することを考える。
- `PassengerId`は削除する
- `Name`, `Ticket`, `Cabin`も削除する
- 文字列はエラーになるため、数値に変換する
- 欠損はエラーとならないため、特に処理は行わない

#+begin_src python :session
  from sklearn.preprocessing import LabelEncoder

  # 変数PassengerIdを除外する
  train_x = train_x.drop(['PassengerId'], axis=1)
  test_x = test_x.drop(['PassengerId'], axis=1)

  # 変数Name, Ticket, Cabinを除外する
  train_x = train_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)
  test_x = test_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)

  # それぞれのカテゴリ変数にLabel encodingを適用する
  for c in ['Sex', 'Embarked']:
      # 学習データに基づいてどう変換するかを定める
      le = LabelEncoder()
      le.fit(train_x[c].fillna('NA'))

      # 学習データ、テストデータを変換する
      train_x[c] = le.transform(train_x[c].fillna('NA'))
      test_x[c] = le.transform(test_x[c].fillna('NA'))
#+end_src

#+RESULTS:

#+begin_src python :session
train_x
#+end_src

#+RESULTS:
#+begin_example
     Pclass  Sex   Age  SibSp  Parch     Fare  Embarked
0         3    1  22.0      1      0   7.2500         3
1         1    0  38.0      1      0  71.2833         0
2         3    0  26.0      0      0   7.9250         3
3         1    0  35.0      1      0  53.1000         3
4         3    1  35.0      0      0   8.0500         3
..      ...  ...   ...    ...    ...      ...       ...
886       2    1  27.0      0      0  13.0000         3
887       1    0  19.0      0      0  30.0000         3
888       3    0   NaN      1      2  23.4500         3
889       1    1  26.0      0      0  30.0000         0
890       3    1  32.0      0      0   7.7500         2

[891 rows x 7 columns]
#+end_example

* モデルの作成
GBDTのライブラリの1つであるxgboostを用いてモデルを作成する
#+begin_src python :session
  from xgboost import XGBClassifier
  import numpy as np

  # モデルの作成および学習データを与えての学習
  model = XGBClassifier(n_estimators=20, random_state=71)
  model.fit(train_x, train_y)

  # テストデータの予測値を確率で出力する
  pred = model.predict_proba(test_x)[:, 1]

  # テストデータの予測値を二値に変換する
  pred_label = np.where(pred > 0.5, 1, 0)

  # 提出用ファイルの作成
  submission = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': pred_label})
  submission.to_csv('submission_first.csv', index=False)
#+end_src

#+RESULTS:
: None

* モデルの評価
クロスバリデーションで評価する
クロスバリデーションは、データを複数のブロックに分けて、
うち１つを評価用のデータとし、残りを学習用のデータをすることを
評価用のデータを入れ替えて繰り返す方法です。
#+begin_src python :session
  from sklearn.metrics import log_loss, accuracy_score
  from sklearn.model_selection import KFold

  # 各foldのスコアを保持するリスト
  scores_accuracy = []
  scores_logloss  = []

  # クロスバリデーションを行う
  # 学習データを4つに分割し、うち1つをバリデーションデータをすることを、
  # バリデーションデータを変えて繰り返す
  kf = KFold(n_splits=4, shuffle=True, random_state=71)
  for tr_idx, va_idx in kf.split(train_x):
      # 学習データを学習データとバリデーションデータに分ける
      tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]
      tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]

      # モデルの学習を行う
      model = XGBClassifier(n_estimators=20, random_state=71)
      model.fit(tr_x, tr_y)

      # バリデーションデータの予測値を確率で出力する
      va_pred = model.predict_proba(va_x)[:, 1]

      # バリデーションデータでのスコアを計算する
      logloss = log_loss(va_y, va_pred)
      accuracy = accuracy_score(va_y, va_pred > 0.5)

      # そのfoldのスコアを保存する
      scores_logloss.append(logloss)
      scores_accuracy.append(accuracy)

  # 各foldのスコアの平均値を出力する
  logloss = np.mean(scores_logloss)
  acuuracy = np.mean(scores_accuracy)
  print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')
#+end_src

#+RESULTS:
: None
